{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test the trained model with visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from dataloaders import Dataloader\n",
    "from models.ViT_MAE.vit_translation import ViT_Translation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load saved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model, path_to_checkpoint):\n",
    "    config_path = os.path.join(path_to_checkpoint, 'config.json')\n",
    "    parameters_path = os.path.join(path_to_checkpoint, 'parameters.torch')\n",
    "    with open(config_path) as f:\n",
    "        config = json.load(f)\n",
    "    model = model(**config[\"model\"])\n",
    "    checkpoint = torch.load(parameters_path)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "path_to_checkpoint = \"/nfs/home/clruben/workspace/nst/models/ViT_MAE/checkpoints/vit_mae-08-04-2023-09_33_00\"\n",
    "model = load_model(ViT_Translation, path_to_checkpoint)\n",
    "\n",
    "device = torch.device(\"cuda:0\")\n",
    "model.to(device)\n",
    "\n",
    "model.eval()\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Load test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source = \"/nfs/home/clruben/workspace/nst/data/\"\n",
    "\n",
    "ct = Dataloader(source, \"test\", \"CT\")\n",
    "mr = Dataloader(source, \"test\", \"MR\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Test the model on some images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_numpy(torch_variable):\n",
    "    return torch_variable.detach().cpu().numpy()\n",
    "\n",
    "mr_image = torch.tensor(mr[0]).to(device)\n",
    "with torch.no_grad():\n",
    "    outputs = model(mr_image)\n",
    "\n",
    "pred = to_numpy(model.unpatchify(outputs.pred))\n",
    "mask = to_numpy(outputs.mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_img = mr[0][0][0]\n",
    "pred_img = pred[0][0]\n",
    "mask_reshaped = mask[0].reshape(32,32)\n",
    "def apply_mask(img, mask):\n",
    "    img_copy = img.copy()\n",
    "    mask_size = img.shape[0]//mask.shape[0]\n",
    "    for i in range(mask.shape[0]):\n",
    "        for j in range(mask.shape[1]):\n",
    "            if mask[i,j] == 1:\n",
    "                img_copy[i*mask_size:(i+1)*mask_size, j*mask_size:(j+1)*mask_size] = 0\n",
    "    return img_copy\n",
    "masked_img = apply_mask(input_img, mask_reshaped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show input_img, masked_img, and pred_img side by side with subplots\n",
    "f, axarr = plt.subplots(1,3, figsize=(8, 8))\n",
    "\n",
    "axarr[0].imshow(input_img, cmap='gray')\n",
    "axarr[0].axis('off')\n",
    "axarr[1].imshow(masked_img, cmap='gray')\n",
    "axarr[1].axis('off')\n",
    "axarr[2].imshow(pred_img, cmap='gray')\n",
    "axarr[2].axis('off')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
